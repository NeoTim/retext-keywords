<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>retext-keywords</title>
    <style>
    textarea, div {
      width: 100%;
      max-width: 40rem;
      margin: 0;
      box-sizing: border-box;
    }
    </style>
  </head>
  <body>
    <h1>retext-keywords</h1>
    <p>A quick demo of <a href="https://github.com/wooorm/retext-keywords">retext-keywords</a>.</p>
    <p>Raise any issues on <a href="https://github.com/wooorm/retext-keywords/issues">Github</a>.</p>
    <textarea rows="20" cols="80" autofocus>Keyword extraction with Retext: First four paragraphs on Term Extraction from Wikipedia.

Terminology mining, term extraction, term recognition, or glossary extraction, is a subtask of information extraction. The goal of terminology extraction is to automatically extract relevant terms from a given corpus.

In the semantic web era, a growing number of communities and networked enterprises started to access and interoperate through the internet. Modeling these communities and their information needs is important for several web applications, like topic-driven web crawlers,[1] web services,[2] recommender systems,[3] etc. The development of terminology extraction is essential to the language industry.

One of the first steps to model the knowledge domain of a virtual community is to collect a vocabulary of domain-relevant terms, constituting the linguistic surface manifestation of domain concepts. Several methods to automatically extract technical terms from domain-specific document warehouses have been described in the literature.[4][5][6][7][8][9][10][11][12][13][14][15][16]

Typically, approaches to automatic term extraction make use of linguistic processors (part of speech tagging, phrase chunking) to extract terminological candidates, i.e. syntactically plausible terminological noun phrases, NPs (e.g. compounds "credit card", adjective-NPs "local tourist information office", and prepositional-NPs "board of directors" - in English, the first two constructs are the most frequent). Terminological entries are then filtered from the candidate list using statistical and machine learning methods. Once filtered, because of their low ambiguity and high specificity, these terms are particularly useful for conceptualizing a knowledge domain or for supporting the creation of a domain ontology. Furthermore, terminology extraction is a very useful starting point for semantic similarity, knowledge management, human translation and machine translation, etc.</textarea>
    <div></div>
    <script src="build.js"></script>
  </body>
</html>
